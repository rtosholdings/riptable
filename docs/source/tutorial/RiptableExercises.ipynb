{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riptable Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workbook is meant to give practical experience with the key ideas & functionality of Riptable.\n",
    "\n",
    "To complete it, you'll need to consult the [Intro to Riptable](tutorial.ipynb).\n",
    "\n",
    "Depending on your preferred learning style, you can read through the entire intro guide first or start with the exercises and refer to the guide as needed.\n",
    "\n",
    "Note that the intro guide has more coverage and detail, so it's well worth reading in full at some point.\n",
    "\n",
    "If you have any questions or comments, email RiptableDocumentation@sig.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To download this notebook, right click on the link and Save link as...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='RiptableExercises.ipynb' target='_blank'>RiptableExercises.ipynb</a><br>"
      ],
      "text/plain": [
       "X:\\btcache\\scratch\\johnsonc\\jupyter\\Tutorial\\Tutorial_GitLab\\RiptableExercises.ipynb"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate notebook download link\n",
    "from IPython.display import FileLink\n",
    "print('To download this notebook, right click on the link and Save link as...')\n",
    "FileLink('RiptableExercises.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import riptable as rt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the Riptable Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datasets** are the core class of riptable. \n",
    "\n",
    "They are tables of data, consisting of a series of **columns** of the same length (sometimes referred to as **fields**).\n",
    "\n",
    "Structurally, they behave like python dictionaries, and can be created directly from one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll familiarize ourselves with Datasets by manually constructing one by generating fake sample data using `np.random.default_rng().choice(...)` or similar.\n",
    "\n",
    "In real life they will essentially always be generated from world data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, create a python dictionary with two fields of the same length (>1000); one column of stock prices and one of symbols.**\n",
    "\n",
    "**Make sure the symbols have duplicates, for later aggregation exercises.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**Create a riptable dataset from this, using** `rt.Dataset(my_dict)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily append more columns to a dataset.\n",
    "\n",
    "**Add a new column of integer trade size, using** `my_dset.Size = `."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns can be referred with brackets around a string name as well. This is typically used when the column name comes from a variable.\n",
    "\n",
    "**Add a new column of booleans indicating whether you traded this trade, using** `my_dset['MyTrade'] =`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add a new column of string \"Buy\" or \"Sell\" indicating the customer direction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riptable will convert these lists to the riptable **FastArray** container and cast the data to an appropriate numpy datatype.\n",
    "\n",
    "**View the datatypes with** `my_dset.dtypes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View some sample rows of the dataset using** `.sample()`.\n",
    "\n",
    "You should use this instead of `.head()` because the initial rows of a dataset are often unrepresentative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View distributional stats of the numerical fields of your dataset with** `.describe()`.\n",
    "\n",
    "You can call this on a single column as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform simple operation on riptable columns with normal python syntax. Riptable will do them to the whole column at once, efficiently.\n",
    "\n",
    "**Create a new column by performing scalar arithmetic on one of your numeric columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as the columns are the same size (as is guaranteed if they're in the same dataset) you can perform combining operations the same way.\n",
    "\n",
    "**Create a new column of total price paid for the trade by multiplying two existing columns together.**\n",
    "\n",
    "Riptable will automatically upcast types as necessary to preserve information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many built-in functions as well, which you call with either `my_dset.field.function()` or `rt.function(my_dset.field)` syntax.\n",
    "\n",
    "**Find the unique Symbols in your dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date/Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riptable has three main date/time types: `Date`, `DateTimeNano`, and `TimeSpan`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Give each row of your dataset an** `rt.Date`.\n",
    "\n",
    "**Make sure they're not all different, but still include days from multiple months.**\n",
    "\n",
    "Note that due to Riptable idiosyncracies you need to generate a list of yyyymmdd strings and pass into the `rt.Date(...)` constructor, not construct Dates individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Give each row a unique(ish)** `TimeSpan` **as a trade time.** \n",
    "\n",
    "You can instantiate them using `rt.TimeSpan(hours_var, unit='h')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a DateTimeNano of the combined TradeDateTime by simple addition. Riptable knows how to sum the types.**\n",
    "\n",
    "Be careful here, by default you'll get a GMT timezone, you can force NYC with `rt.DateTimeNano(..., from_tz='NYC')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reverse this operation and get out separate dates and times from a DateTimeNano, you can call `rt.Date(my_DateTimeNano)` and `my_DateTimeNano.time_since_midnight()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a new month name column by using the** `.strftime` **function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create another new month column by using the** `.start_of_month` **attribute.**\n",
    "\n",
    "This is nice for grouping because it will automatically sort correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riptable has two sorts, `sort_copy` (which preserves the original dataset) and `sort_inplace`, which is faster and more memory-efficient if you don't need the original data order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sort your dataset by TradeDateTime.**\n",
    "\n",
    "This is the natural ordering of a list of trades, so do it in-place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Filtering is the principal way to work with a subset of your data in riptable. It is commonly used for looking at a restricted set of trades matching some criterion you care about.\n",
    "\n",
    "Except in rare instances, though, you should maintain your dataset in its full size, and only apply a filter when performing a final computation.\n",
    "\n",
    "This will avoid unnecessary data duplication and improve speed & memory usage.\n",
    "\n",
    "**Construct a filter of only your sales. (A filter is a column of Booleans which is true only for the rows you're interested in.)** \n",
    "\n",
    "You can combine filters using & or |. Be careful to always wrap expressions in parentheses to avoid an extremely slow call into native python followed by a crash.\n",
    "\n",
    "Always `(my_dset.field1 > 10) & (my_dset.field2 < 5)`, never `my_dset.field1 > 10 & my_dset.field2 > 5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Compute the total Trade Size, filtered for only your sales.**\n",
    "\n",
    "For this and many other instances, you can & should pass your filter into the `filter` kwarg of the `.nansum(...)` call. \n",
    "\n",
    "This allows riptable to perform the filtering during the nansum computation, rather than instantiating a new column and then summing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count how many times you sold each symbol.**\n",
    "\n",
    "Here the `.count()` function doesn't accept a `filter` kwarg, so you must fall back to explicitly filtering the `Symbol` field before counting.\n",
    "\n",
    "Be careful that you only filter down the `Symbol` field, not the entire dataset, otherwise you are wasting a lot of compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categoricals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've been operating on your symbol column as a column of strings.\n",
    "\n",
    "However, it's far more efficient when you have a large column with many repeats to use a categorical, which assigns each unique value a number, and stores the labels & numbers separately.\n",
    "\n",
    "This is memory-efficient, and also computationally efficient, as riptable can peform operations on the unique values, then expand out to the full vector appropriately.\n",
    "\n",
    "**Make a new column of your string column converted to a categorical, using** `rt.Cat(column)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform the same filtered count from above, on the categorical.**\n",
    "\n",
    "The categorical `.count()` admits a `filter` kwarg, which makes it simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categoricals can be used as groupings. When you call a numeric function on a categorical and pass numeric columns in, riptable knows to do the calculation per-group.\n",
    "\n",
    "**Compute the total amount of contracts sold by customers in each symbol.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `transform=True` kwarg in a categorical operation performs the aggregation, then *transforms* it back up to the original shape of the categorical, giving each row the appropriate value from its group.\n",
    "\n",
    "**Make a new column which is the average trade price, per symbol.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspect with** `.sample()` **to confirm that this value is consistent for rows with matching symbol.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to perform a custom operation on each categorical, you can pass in a function with `.apply_reduce` (which aggregates) or `.apply_nonreduce` (which is like `transform=True`).\n",
    "\n",
    "Note that the custom function you pass needs to expect a FastArray, and output a scalar (`apply_reduce`) or same-length FastArray (`apply_nonreduce`).\n",
    "\n",
    "**Find, for each symbol, the trade size of the second trade occuring in the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you want to aggregate based on multiple values. In these cases we use multi-key categoricals.\n",
    "\n",
    "**Use a multi-key categorical to compute the average size per symbol-month pair.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Accumulating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregating over two values for human viewing is often most conveniently done with an accum. \n",
    "\n",
    "**Use** `Accum2` **to compute the average size per symbol-month pair.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average numbers can be meaningless. It is often better to consider relative percentage instead.\n",
    "\n",
    "**Use** `accum_ratiop` **to compute the fraction of total volume done by each symbol-month pair.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main types of merges.\n",
    "\n",
    "First is `merge_lookup`. This is used for enriching one (typically large) dataset with information from another (typically small) dataset.\n",
    "\n",
    "**Create a new dataset with one row per symbol from your dataset, and a second column of who trades each symbol.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enrich the main dataset by putting the correct trader into each row.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second type of merge is `merge_asof`, which is used for fuzzy alignment between two datasets, typically by time (though often by other variables).\n",
    "\n",
    "**Create a new index price dataset with one price per minute, which covers all the Dates in your dataset.** \n",
    "\n",
    "The index price doesn't need to be reasonable.\n",
    "\n",
    "Each row should have a DateTimeNano as the datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use** `merge_asof` **to get the most recent Index Price associated with each trade in your main dataset.**\n",
    "\n",
    "Note both datasets need to be sorted for merge_asof.\n",
    "\n",
    "The `on` kwarg is the numeric/time field that looks for close matches.\n",
    "\n",
    "The `by` kwarg is not necessary here, but could constrain the match to a subset if, for example, you had multiple indices and a column of which one each row is associated with.\n",
    "\n",
    "**Use** `direction='backward'` **to ensure you're not biasing your data by looking into the future!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving/Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The native riptable filetype is .sds. It's the fastest way to save & load your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save out your dataset to file using** `rt.save_sds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delete your dataset to free up memory using the native python** `del my_dset`.\n",
    "\n",
    "Note that if there are references to the dataset in other objects you may not actually free up memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reload your saved dataset from disk with** `rt.load_sds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load from h5 files (a common file type at SIG), use `rt.load_h5(file)`.\n",
    "\n",
    "To load from csv files, use the slow but robust pandas loader, with `rt.Dataset.from_pandas(pd.read_csv(file))`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
